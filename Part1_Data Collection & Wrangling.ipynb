{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction of Air Quality Index (primary pollutant PM 2.5) of Los Angeles, California"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import requests # will download the data in form of html\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "\n",
    "import missingno as msno\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 1: Los Angeles Intl Airport climate data: https://en.tutiempo.net/climate/ws-722950.html\n",
    "### Dataset 2: Los Angeles USC Campus Downtown climate data: https://en.tutiempo.net/climate/ws-722874.html\n",
    "\n",
    "These datasets contain the historical climate data of two weather stations in Los Angeles, CA, United States. The website provides a wide range of data starting from 1973-2019. We want to download the climate data for 12 months through 2010-2020.\n",
    "    \n",
    "Interpretation annual average climate values:\n",
    "\n",
    "- T: Average Temperature (°C)\n",
    "- TM: Maximum temperature (°C)\n",
    "- Tm: Minimum temperature (°C)\n",
    "- SLP: Atmospheric pressure at sea level (hPa)\n",
    "- H: Average relative humidity (%)\n",
    "- PP: Total rainfall and / or snowmelt (mm)\n",
    "- VV: Average visibility (Km)\n",
    "- V: Average wind speed (Km/h)\n",
    "- VM: Maximum sustained wind speed (Km/h)\n",
    "- VG: Maximum speed of wind (Km/h)\n",
    "- RA: Indicate if there was rain or drizzle (In the monthly average, total days it rained)\n",
    "- SN: Snow indicator (In the monthly average, total days that snowed)\n",
    "- TS: Indicates whether there storm (In the monthly average, Total days with thunderstorm)\n",
    "- FG: Indicates whether there was fog (In the monthly average, Total days with fog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection\n",
    "\n",
    "### A function that downloads the html data tables in the local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_html(ws_value, station):\n",
    "    \n",
    "    for year in range(2010, 2021): # we want the data for the years from 2010 to 2020\n",
    "        for month in range (1, 13):\n",
    "            if (month < 10):\n",
    "                url = \"https://en.tutiempo.net/climate/0{}-{}/ws-{}.html\".format(month, year, ws_value) # month is less than 10 means month takes 1 digit \n",
    "            else:\n",
    "                url = \"https://en.tutiempo.net/climate/{}-{}/ws-{}.html\".format(month, year, ws_value) # here months are 10, 11 and 12\n",
    "                \n",
    "            texts  = requests.get(url)\n",
    "            text_utf = texts.text.encode('utf = 8') # please follow the link if you want to know more about encoding \"https://kunststube.net/encoding/\"\n",
    "        \n",
    "            if not os.path.exists(\"Data_LA/html_data_LA/{}/{}\".format(station, year)):\n",
    "                os.makedirs(\"Data_LA/html_data_LA/{}/{}\".format(station, year)) # creating the directory here if already not exists \n",
    "            with open(\"Data_LA/html_data_LA/{}/{}/{}.html\".format(station, year, month), \"wb\") as output:\n",
    "                output.write(text_utf) # writing from text_utf to folders created in Data/html_data/years as html\n",
    "            \n",
    "        sys.stdout.flush() # While using stdout, data is stored in buffer memory (for some time or until the memory gets filled) before it gets written to terminal. \n",
    "        # Using flush() forces to empty the buffer and write to terminal even before buffer has empty space.        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to retrieve data 139.79031777381897\n"
     ]
    }
   ],
   "source": [
    "# we want to see how long does it take to retrieve the html data files\n",
    "start_time = time.time()\n",
    "retrieve_html(722950, 'LAX')\n",
    "stop_time = time.time()\n",
    "print(\"Time taken to retrieve data {}\".format(stop_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to retrieve data 137.08098697662354\n"
     ]
    }
   ],
   "source": [
    "# we want to see how long does it take to retrieve the html data files\n",
    "start_time = time.time()\n",
    "retrieve_html(722874, 'USC_Downtown')\n",
    "stop_time = time.time()\n",
    "print(\"Time taken to retrieve data {}\".format(stop_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling\n",
    "\n",
    "### Data Wrangling of Dataset 1: Los Angeles Intl Airport climate data\n",
    "\n",
    "- We will convert all the columns into numeric columns. We will take care of the 'Date' column and convert its type to datetime. \n",
    "\n",
    "- We will convert all the '-' into numpy.NaN.\n",
    "\n",
    "- We want to keep only ['Date', 'T', 'TM', 'Tm', 'SLP', 'H', 'PP', 'VV', 'V', 'VM'] columns as other columns don't provide much data.\n",
    "\n",
    "- As a very little portion of data (less than 5%) is missing, we will impute the median of the feature/column to replace the numeric missing data\n",
    "\n",
    "- We will generate the Pandas Profile Report to be able to explore each dataset (month-wise) more.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monthly_weather_data(month, year, station):\n",
    "\n",
    "    html_data = pd.read_html('Data_LA/html_data_LA/{}/{}/{}.html'.format(station, year, month))\n",
    "    df = pd.DataFrame(html_data[2])\n",
    "    df = df.iloc[:-2]\n",
    "    df = df.apply(pd.to_numeric, errors='ignore')\n",
    "    \n",
    "    if (month in (1, 3, 5, 7, 8, 10, 12)):\n",
    "        df['Date'] = pd.date_range(start ='{}/01/{}'.format(month, year), end ='{}/31/{}'.format(month, year), freq='D')\n",
    "    elif (month in (4, 6, 9, 11)):\n",
    "        df['Date'] = pd.date_range(start ='{}/01/{}'.format(month, year), end ='{}/30/{}'.format(month, year), freq='D')\n",
    "    elif month == 2 and year in (2012, 2016, 2020):\n",
    "        df['Date'] = pd.date_range(start ='{}/01/{}'.format(month, year), end ='{}/29/{}'.format(month, year), freq='D')\n",
    "    elif month == 2 and year in (2010, 2011, 2013, 2014, 2015, 2017, 2018, 2019):\n",
    "        df['Date'] = pd.date_range(start ='{}/01/{}'.format(month, year), end ='{}/28/{}'.format(month, year), freq='D')\n",
    "\n",
    "    cols_to_keep = ['Date', 'T', 'TM', 'Tm', 'SLP', 'H', 'PP', 'VV', 'V', 'VM']\n",
    "    df = df[cols_to_keep]\n",
    "\n",
    "    df = df.dropna(axis = 'rows', how = 'all')\n",
    "    \n",
    "    df = df.replace('-', np.nan)\n",
    "\n",
    "    col = ['T', 'TM', 'Tm', 'SLP', 'H', 'PP', 'VV', 'V', 'VM']\n",
    "    df = df.apply(pd.to_numeric, errors='ignore')\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df['Date'] = df['Date'].apply(lambda x: x.strftime('%d-%m-%Y'))\n",
    "    df = df.dropna(how = 'all')\n",
    "    \n",
    "    return df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yearly_weather_data(year, station):\n",
    "    \n",
    "    a = pd.concat([monthly_weather_data(1, year, station), monthly_weather_data(2, year, station), monthly_weather_data(3, year, station), monthly_weather_data(4, year, station), \\\n",
    "                monthly_weather_data(5, year, station), monthly_weather_data(6, year, station), monthly_weather_data(7, year, station), monthly_weather_data(8, year, station), \\\n",
    "                monthly_weather_data(9, year, station), monthly_weather_data(10, year, station), monthly_weather_data(11, year, station), monthly_weather_data(12, year, station)])\n",
    "    \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to retrieve data 3.850970506668091\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "climate_dat_2010_LAX = yearly_weather_data(2010, 'LAX')\n",
    "climate_dat_2011_LAX = yearly_weather_data(2011, 'LAX')\n",
    "climate_dat_2012_LAX = yearly_weather_data(2012, 'LAX')\n",
    "climate_dat_2013_LAX = yearly_weather_data(2013, 'LAX')\n",
    "climate_dat_2014_LAX = yearly_weather_data(2014, 'LAX')\n",
    "climate_dat_2015_LAX = yearly_weather_data(2015, 'LAX')\n",
    "climate_dat_2016_LAX = yearly_weather_data(2016, 'LAX')\n",
    "climate_dat_2017_LAX = yearly_weather_data(2017, 'LAX')\n",
    "climate_dat_2018_LAX = yearly_weather_data(2018, 'LAX')\n",
    "climate_dat_2019_LAX = yearly_weather_data(2019, 'LAX')\n",
    "\n",
    "stop_time = time.time()\n",
    "print(\"Time taken to retrieve data {}\".format(stop_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>T</th>\n",
       "      <th>TM</th>\n",
       "      <th>Tm</th>\n",
       "      <th>SLP</th>\n",
       "      <th>H</th>\n",
       "      <th>PP</th>\n",
       "      <th>VV</th>\n",
       "      <th>V</th>\n",
       "      <th>VM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01-01-2019</td>\n",
       "      <td>12.1</td>\n",
       "      <td>17.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1016.4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16.1</td>\n",
       "      <td>9.1</td>\n",
       "      <td>29.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02-01-2019</td>\n",
       "      <td>11.2</td>\n",
       "      <td>16.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1021.3</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16.1</td>\n",
       "      <td>8.5</td>\n",
       "      <td>18.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03-01-2019</td>\n",
       "      <td>12.4</td>\n",
       "      <td>18.9</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1022.5</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04-01-2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05-01-2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>06-01-2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>07-01-2019</td>\n",
       "      <td>12.5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>1022.4</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2.03</td>\n",
       "      <td>10.5</td>\n",
       "      <td>15.4</td>\n",
       "      <td>25.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>08-01-2019</td>\n",
       "      <td>14.8</td>\n",
       "      <td>21.7</td>\n",
       "      <td>10.6</td>\n",
       "      <td>1020.3</td>\n",
       "      <td>70.0</td>\n",
       "      <td>3.30</td>\n",
       "      <td>16.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>22.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>09-01-2019</td>\n",
       "      <td>13.9</td>\n",
       "      <td>21.7</td>\n",
       "      <td>8.9</td>\n",
       "      <td>1019.8</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15.1</td>\n",
       "      <td>7.6</td>\n",
       "      <td>31.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10-01-2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date     T    TM    Tm     SLP     H    PP    VV     V    VM\n",
       "0  01-01-2019  12.1  17.8   5.0  1016.4  21.0  0.00  16.1   9.1  29.4\n",
       "1  02-01-2019  11.2  16.7   3.9  1021.3  19.0  0.00  16.1   8.5  18.3\n",
       "2  03-01-2019  12.4  18.9   3.9  1022.5  33.0  0.00  16.1   8.0  20.6\n",
       "3  04-01-2019   NaN   NaN   NaN     NaN   NaN   NaN   NaN   NaN   NaN\n",
       "4  05-01-2019   NaN   NaN   NaN     NaN   NaN   NaN   NaN   NaN   NaN\n",
       "5  06-01-2019   NaN   NaN   NaN     NaN   NaN   NaN   NaN   NaN   NaN\n",
       "6  07-01-2019  12.5  15.0   9.4  1022.4  82.0  2.03  10.5  15.4  25.9\n",
       "7  08-01-2019  14.8  21.7  10.6  1020.3  70.0  3.30  16.1   8.0  22.2\n",
       "8  09-01-2019  13.9  21.7   8.9  1019.8  78.0  0.00  15.1   7.6  31.7\n",
       "9  10-01-2019   NaN   NaN   NaN     NaN   NaN   NaN   NaN   NaN   NaN"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "climate_dat_2019_LAX.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to retrieve data 3.8611385822296143\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "climate_dat_2010_Downtown = yearly_weather_data(2010, 'USC_Downtown')\n",
    "climate_dat_2011_Downtown = yearly_weather_data(2011, 'USC_Downtown')\n",
    "climate_dat_2012_Downtown = yearly_weather_data(2012, 'USC_Downtown')\n",
    "climate_dat_2013_Downtown = yearly_weather_data(2013, 'USC_Downtown')\n",
    "climate_dat_2014_Downtown = yearly_weather_data(2014, 'USC_Downtown')\n",
    "climate_dat_2015_Downtown = yearly_weather_data(2015, 'USC_Downtown')\n",
    "climate_dat_2016_Downtown = yearly_weather_data(2016, 'USC_Downtown')\n",
    "climate_dat_2017_Downtown = yearly_weather_data(2017, 'USC_Downtown')\n",
    "climate_dat_2018_Downtown = yearly_weather_data(2018, 'USC_Downtown')\n",
    "climate_dat_2019_Downtown = yearly_weather_data(2019, 'USC_Downtown')\n",
    "\n",
    "stop_time = time.time()\n",
    "print(\"Time taken to retrieve data {}\".format(stop_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>T</th>\n",
       "      <th>TM</th>\n",
       "      <th>Tm</th>\n",
       "      <th>SLP</th>\n",
       "      <th>H</th>\n",
       "      <th>PP</th>\n",
       "      <th>VV</th>\n",
       "      <th>V</th>\n",
       "      <th>VM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01-01-2019</td>\n",
       "      <td>10.4</td>\n",
       "      <td>17.2</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1016.4</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02-01-2019</td>\n",
       "      <td>9.3</td>\n",
       "      <td>17.2</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1021.3</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16.1</td>\n",
       "      <td>2.2</td>\n",
       "      <td>11.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03-01-2019</td>\n",
       "      <td>11.3</td>\n",
       "      <td>19.4</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1022.3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16.1</td>\n",
       "      <td>1.7</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04-01-2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05-01-2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>06-01-2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>07-01-2019</td>\n",
       "      <td>12.5</td>\n",
       "      <td>16.1</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1022.5</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.6</td>\n",
       "      <td>5.4</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>08-01-2019</td>\n",
       "      <td>14.7</td>\n",
       "      <td>22.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1020.2</td>\n",
       "      <td>66.0</td>\n",
       "      <td>4.32</td>\n",
       "      <td>14.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>09-01-2019</td>\n",
       "      <td>13.9</td>\n",
       "      <td>19.4</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1019.7</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15.8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10-01-2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date     T    TM    Tm     SLP     H    PP    VV    V    VM\n",
       "0  01-01-2019  10.4  17.2   3.3  1016.4  26.0  0.00  15.8  2.0   9.4\n",
       "1  02-01-2019   9.3  17.2   3.3  1021.3  32.0  0.00  16.1  2.2  11.1\n",
       "2  03-01-2019  11.3  19.4   3.3  1022.3  35.0  0.00  16.1  1.7   9.4\n",
       "3  04-01-2019   NaN   NaN   NaN     NaN   NaN   NaN   NaN  NaN   NaN\n",
       "4  05-01-2019   NaN   NaN   NaN     NaN   NaN   NaN   NaN  NaN   NaN\n",
       "5  06-01-2019   NaN   NaN   NaN     NaN   NaN   NaN   NaN  NaN   NaN\n",
       "6  07-01-2019  12.5  16.1   7.8  1022.5  81.0  0.76  11.6  5.4  16.5\n",
       "7  08-01-2019  14.7  22.2  10.0  1020.2  66.0  4.32  14.6  2.8   9.4\n",
       "8  09-01-2019  13.9  19.4   8.3  1019.7  71.0  0.00  15.8  1.1   9.4\n",
       "9  10-01-2019   NaN   NaN   NaN     NaN   NaN   NaN   NaN  NaN   NaN"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "climate_dat_2019_Downtown.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Now we have climate data of different regions of Los Angeles i.e., LAX Airpot and Downtown. We need to combine these two datasets and take a mean according to each date.*\n",
    "\n",
    "- We will concatenate these DataFrames.\n",
    "- We will use 'groupby' to find the mean of the climate features according to each date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def climate_data(df1, df2):\n",
    "    \n",
    "    frames = [df1, df2]\n",
    "    df = pd.concat(frames)\n",
    "    df = df.groupby(['Date'])['T', 'TM', 'Tm', 'SLP', 'H', 'PP', 'VV', 'V', 'VM'].mean()\n",
    "    df = df.dropna(axis = 'rows', how = 'all')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_data_2010 = climate_data(climate_dat_2010_LAX, climate_dat_2010_Downtown)\n",
    "climate_data_2011 = climate_data(climate_dat_2011_LAX, climate_dat_2011_Downtown)\n",
    "climate_data_2012 = climate_data(climate_dat_2012_LAX, climate_dat_2012_Downtown)\n",
    "climate_data_2013 = climate_data(climate_dat_2013_LAX, climate_dat_2013_Downtown)\n",
    "climate_data_2014 = climate_data(climate_dat_2014_LAX, climate_dat_2014_Downtown)\n",
    "climate_data_2015 = climate_data(climate_dat_2015_LAX, climate_dat_2015_Downtown)\n",
    "climate_data_2016 = climate_data(climate_dat_2016_LAX, climate_dat_2016_Downtown)\n",
    "climate_data_2017 = climate_data(climate_dat_2017_LAX, climate_dat_2017_Downtown)\n",
    "climate_data_2018 = climate_data(climate_dat_2018_LAX, climate_dat_2018_Downtown)\n",
    "climate_data_2019 = climate_data(climate_dat_2019_LAX, climate_dat_2019_Downtown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T</th>\n",
       "      <th>TM</th>\n",
       "      <th>Tm</th>\n",
       "      <th>SLP</th>\n",
       "      <th>H</th>\n",
       "      <th>PP</th>\n",
       "      <th>VV</th>\n",
       "      <th>V</th>\n",
       "      <th>VM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01-01-2010</th>\n",
       "      <td>14.75</td>\n",
       "      <td>20.85</td>\n",
       "      <td>9.20</td>\n",
       "      <td>1023.95</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.10</td>\n",
       "      <td>4.20</td>\n",
       "      <td>16.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-02-2010</th>\n",
       "      <td>13.70</td>\n",
       "      <td>19.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1013.95</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.65</td>\n",
       "      <td>4.50</td>\n",
       "      <td>12.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-03-2010</th>\n",
       "      <td>14.80</td>\n",
       "      <td>20.15</td>\n",
       "      <td>9.90</td>\n",
       "      <td>1017.85</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.10</td>\n",
       "      <td>4.90</td>\n",
       "      <td>18.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-04-2010</th>\n",
       "      <td>13.05</td>\n",
       "      <td>16.40</td>\n",
       "      <td>9.50</td>\n",
       "      <td>1013.30</td>\n",
       "      <td>54.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.10</td>\n",
       "      <td>12.50</td>\n",
       "      <td>24.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-05-2010</th>\n",
       "      <td>17.15</td>\n",
       "      <td>21.40</td>\n",
       "      <td>12.20</td>\n",
       "      <td>1012.20</td>\n",
       "      <td>48.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.10</td>\n",
       "      <td>11.75</td>\n",
       "      <td>33.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-06-2010</th>\n",
       "      <td>17.80</td>\n",
       "      <td>23.35</td>\n",
       "      <td>16.15</td>\n",
       "      <td>1015.30</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.45</td>\n",
       "      <td>6.00</td>\n",
       "      <td>14.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-07-2010</th>\n",
       "      <td>18.70</td>\n",
       "      <td>22.50</td>\n",
       "      <td>16.30</td>\n",
       "      <td>1010.30</td>\n",
       "      <td>76.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.80</td>\n",
       "      <td>5.85</td>\n",
       "      <td>17.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-08-2010</th>\n",
       "      <td>19.30</td>\n",
       "      <td>23.65</td>\n",
       "      <td>16.95</td>\n",
       "      <td>1013.60</td>\n",
       "      <td>70.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.25</td>\n",
       "      <td>6.10</td>\n",
       "      <td>15.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-09-2010</th>\n",
       "      <td>19.05</td>\n",
       "      <td>24.70</td>\n",
       "      <td>15.00</td>\n",
       "      <td>1011.70</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.75</td>\n",
       "      <td>7.85</td>\n",
       "      <td>17.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-10-2010</th>\n",
       "      <td>23.35</td>\n",
       "      <td>29.10</td>\n",
       "      <td>20.45</td>\n",
       "      <td>1011.50</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.65</td>\n",
       "      <td>5.85</td>\n",
       "      <td>15.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                T     TM     Tm      SLP     H   PP     VV      V     VM\n",
       "Date                                                                    \n",
       "01-01-2010  14.75  20.85   9.20  1023.95  45.0  0.0  16.10   4.20  16.75\n",
       "01-02-2010  13.70  19.00  10.00  1013.95  70.0  0.0  12.65   4.50  12.95\n",
       "01-03-2010  14.80  20.15   9.90  1017.85  69.0  0.0  16.10   4.90  18.60\n",
       "01-04-2010  13.05  16.40   9.50  1013.30  54.5  0.0  16.10  12.50  24.15\n",
       "01-05-2010  17.15  21.40  12.20  1012.20  48.5  0.0  16.10  11.75  33.25\n",
       "01-06-2010  17.80  23.35  16.15  1015.30  68.0  0.0  15.45   6.00  14.90\n",
       "01-07-2010  18.70  22.50  16.30  1010.30  76.5  0.0   7.80   5.85  17.60\n",
       "01-08-2010  19.30  23.65  16.95  1013.60  70.5  0.0  11.25   6.10  15.80\n",
       "01-09-2010  19.05  24.70  15.00  1011.70  69.0  0.0  11.75   7.85  17.60\n",
       "01-10-2010  23.35  29.10  20.45  1011.50  66.0  0.0  15.65   5.85  15.80"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "climate_data_2010.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 3: https://www.epa.gov/outdoor-air-quality-data/download-daily-data\n",
    "\n",
    "This dataset provides the daily mean concentartion of PM 2.5 which is the main air pollutant of Los Angeles county. We have downloaded the data from the above-mentioned website for the ten years starting from 2010. \n",
    "\n",
    "We want to predict PM 2.5 from the given climate features in dataset 1 of Los Angeles, California . We will use the PM 2.5 data from this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Wrangling of Dataset 3: The Air Quality Index Data of Los Angeles\n",
    "\n",
    "- This dataset contains the PM 2.5 data of different regions of Los Angeles. We will take a mean using the 'groupby' method. \n",
    "- We will atke care of the 'Date' column\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data_PM(path, year):     \n",
    "    \n",
    "    df = pd.read_csv(path) # load dataset\n",
    "\n",
    "    df['Date'] = pd.to_datetime(df['Date'],  errors='coerce') # changing the type of date column to datetime\n",
    "    df['Date'] = df['Date'].apply(lambda x: x.strftime('%d-%m-%Y'))\n",
    "\n",
    "    df = df[['Date', 'Daily Mean PM2.5 Concentration']] # we just need the PM 2.5 column \n",
    "    df.rename(columns= {'Daily Mean PM2.5 Concentration':'PM2.5'}, inplace = True)\n",
    "    df = df.groupby(['Date'])['PM2.5'].mean()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to retrieve data 0.4839920997619629\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "PM_2010 = clean_data_PM('Data_LA/AQI_LA/aqi2010.csv', 2010)\n",
    "PM_2011 = clean_data_PM('Data_LA/AQI_LA/aqi2011.csv', 2011)\n",
    "PM_2012 = clean_data_PM('Data_LA/AQI_LA/aqi2012.csv', 2012)\n",
    "PM_2013 = clean_data_PM('Data_LA/AQI_LA/aqi2013.csv', 2013)\n",
    "PM_2014 = clean_data_PM('Data_LA/AQI_LA/aqi2014.csv', 2014)\n",
    "PM_2015 = clean_data_PM('Data_LA/AQI_LA/aqi2015.csv', 2015)\n",
    "PM_2016 = clean_data_PM('Data_LA/AQI_LA/aqi2016.csv', 2016)\n",
    "PM_2017 = clean_data_PM('Data_LA/AQI_LA/aqi2017.csv', 2017)\n",
    "PM_2018 = clean_data_PM('Data_LA/AQI_LA/aqi2018.csv', 2018)\n",
    "PM_2019 = clean_data_PM('Data_LA/AQI_LA/aqi2019.csv', 2019)\n",
    "\n",
    "stop_time = time.time()\n",
    "print(\"Time taken to retrieve data {}\".format(stop_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "01-01-2019     8.772727\n",
       "01-02-2019     7.227273\n",
       "01-03-2019     9.231250\n",
       "01-04-2019     9.375000\n",
       "01-05-2019     9.509091\n",
       "01-06-2019     9.390909\n",
       "01-07-2019    12.554545\n",
       "01-08-2019    10.864706\n",
       "01-09-2019    12.390909\n",
       "01-10-2019     8.554545\n",
       "Name: PM2.5, dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PM_2019.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_weather_PM(df1, df2):\n",
    "    dff = pd.concat([df1, \n",
    "                df2.to_frame()], \n",
    "                axis=1)\n",
    "    df = dff.dropna(axis = 'rows', how = 'all')\n",
    "    df = df.apply(pd.to_numeric)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2010 = concat_weather_PM(climate_data_2010, PM_2010)\n",
    "df_2011 = concat_weather_PM(climate_data_2011, PM_2011)\n",
    "df_2012 = concat_weather_PM(climate_data_2012, PM_2012)\n",
    "df_2013 = concat_weather_PM(climate_data_2013, PM_2013)\n",
    "df_2014 = concat_weather_PM(climate_data_2014, PM_2014)\n",
    "df_2015 = concat_weather_PM(climate_data_2015, PM_2015)\n",
    "df_2016 = concat_weather_PM(climate_data_2016, PM_2016)\n",
    "df_2017 = concat_weather_PM(climate_data_2017, PM_2017)\n",
    "df_2018 = concat_weather_PM(climate_data_2018, PM_2018)\n",
    "df_2019 = concat_weather_PM(climate_data_2019, PM_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T</th>\n",
       "      <th>TM</th>\n",
       "      <th>Tm</th>\n",
       "      <th>SLP</th>\n",
       "      <th>H</th>\n",
       "      <th>PP</th>\n",
       "      <th>VV</th>\n",
       "      <th>V</th>\n",
       "      <th>VM</th>\n",
       "      <th>PM2.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01-01-2019</th>\n",
       "      <td>11.25</td>\n",
       "      <td>17.50</td>\n",
       "      <td>4.15</td>\n",
       "      <td>1016.40</td>\n",
       "      <td>23.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15.95</td>\n",
       "      <td>5.55</td>\n",
       "      <td>19.40</td>\n",
       "      <td>8.772727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-02-2019</th>\n",
       "      <td>13.15</td>\n",
       "      <td>17.50</td>\n",
       "      <td>9.15</td>\n",
       "      <td>1014.80</td>\n",
       "      <td>76.5</td>\n",
       "      <td>22.86</td>\n",
       "      <td>15.75</td>\n",
       "      <td>5.30</td>\n",
       "      <td>12.95</td>\n",
       "      <td>7.227273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-03-2019</th>\n",
       "      <td>15.15</td>\n",
       "      <td>18.60</td>\n",
       "      <td>13.05</td>\n",
       "      <td>1018.65</td>\n",
       "      <td>82.5</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.65</td>\n",
       "      <td>6.85</td>\n",
       "      <td>13.85</td>\n",
       "      <td>9.231250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-04-2019</th>\n",
       "      <td>21.05</td>\n",
       "      <td>28.30</td>\n",
       "      <td>14.45</td>\n",
       "      <td>1014.00</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16.10</td>\n",
       "      <td>7.50</td>\n",
       "      <td>17.60</td>\n",
       "      <td>9.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-05-2019</th>\n",
       "      <td>15.95</td>\n",
       "      <td>20.25</td>\n",
       "      <td>12.20</td>\n",
       "      <td>1015.65</td>\n",
       "      <td>64.5</td>\n",
       "      <td>0.38</td>\n",
       "      <td>16.10</td>\n",
       "      <td>8.30</td>\n",
       "      <td>22.35</td>\n",
       "      <td>9.509091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-06-2019</th>\n",
       "      <td>16.75</td>\n",
       "      <td>20.80</td>\n",
       "      <td>15.00</td>\n",
       "      <td>1011.45</td>\n",
       "      <td>75.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15.95</td>\n",
       "      <td>7.20</td>\n",
       "      <td>15.00</td>\n",
       "      <td>9.390909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-07-2019</th>\n",
       "      <td>21.35</td>\n",
       "      <td>27.80</td>\n",
       "      <td>17.20</td>\n",
       "      <td>1014.10</td>\n",
       "      <td>66.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15.80</td>\n",
       "      <td>7.85</td>\n",
       "      <td>19.45</td>\n",
       "      <td>12.554545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-08-2019</th>\n",
       "      <td>21.00</td>\n",
       "      <td>25.80</td>\n",
       "      <td>18.05</td>\n",
       "      <td>1014.80</td>\n",
       "      <td>74.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.50</td>\n",
       "      <td>8.25</td>\n",
       "      <td>20.25</td>\n",
       "      <td>10.864706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-09-2019</th>\n",
       "      <td>23.50</td>\n",
       "      <td>29.20</td>\n",
       "      <td>20.00</td>\n",
       "      <td>1011.15</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.70</td>\n",
       "      <td>7.05</td>\n",
       "      <td>17.65</td>\n",
       "      <td>12.390909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-10-2019</th>\n",
       "      <td>19.45</td>\n",
       "      <td>24.15</td>\n",
       "      <td>13.90</td>\n",
       "      <td>1010.25</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16.10</td>\n",
       "      <td>8.60</td>\n",
       "      <td>22.35</td>\n",
       "      <td>8.554545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                T     TM     Tm      SLP     H     PP     VV     V     VM  \\\n",
       "01-01-2019  11.25  17.50   4.15  1016.40  23.5   0.00  15.95  5.55  19.40   \n",
       "01-02-2019  13.15  17.50   9.15  1014.80  76.5  22.86  15.75  5.30  12.95   \n",
       "01-03-2019  15.15  18.60  13.05  1018.65  82.5   0.38  12.65  6.85  13.85   \n",
       "01-04-2019  21.05  28.30  14.45  1014.00  34.5   0.00  16.10  7.50  17.60   \n",
       "01-05-2019  15.95  20.25  12.20  1015.65  64.5   0.38  16.10  8.30  22.35   \n",
       "01-06-2019  16.75  20.80  15.00  1011.45  75.5   0.00  15.95  7.20  15.00   \n",
       "01-07-2019  21.35  27.80  17.20  1014.10  66.5   0.00  15.80  7.85  19.45   \n",
       "01-08-2019  21.00  25.80  18.05  1014.80  74.5   0.00  13.50  8.25  20.25   \n",
       "01-09-2019  23.50  29.20  20.00  1011.15  72.0   0.00  14.70  7.05  17.65   \n",
       "01-10-2019  19.45  24.15  13.90  1010.25  53.0   0.00  16.10  8.60  22.35   \n",
       "\n",
       "                PM2.5  \n",
       "01-01-2019   8.772727  \n",
       "01-02-2019   7.227273  \n",
       "01-03-2019   9.231250  \n",
       "01-04-2019   9.375000  \n",
       "01-05-2019   9.509091  \n",
       "01-06-2019   9.390909  \n",
       "01-07-2019  12.554545  \n",
       "01-08-2019  10.864706  \n",
       "01-09-2019  12.390909  \n",
       "01-10-2019   8.554545  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2019.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                T     TM    Tm      SLP     H   PP     VV    V     VM  \\\n",
      "01-01-2010  14.75  20.85   9.2  1023.95  45.0  0.0  16.10  4.2  16.75   \n",
      "01-02-2010  13.70  19.00  10.0  1013.95  70.0  0.0  12.65  4.5  12.95   \n",
      "\n",
      "                PM2.5  \n",
      "01-01-2010  18.644444  \n",
      "01-02-2010  26.358824  \n",
      "T        174\n",
      "TM       174\n",
      "Tm       174\n",
      "SLP      174\n",
      "H        174\n",
      "PP       174\n",
      "VV       174\n",
      "V        174\n",
      "VM       174\n",
      "PM2.5      0\n",
      "dtype: int64\n",
      "                T    TM    Tm      SLP     H   PP    VV     V     VM  \\\n",
      "01-01-2011  10.55  15.3  5.45  1021.80  38.0  0.0  16.0  5.90  12.05   \n",
      "01-02-2011  14.05  17.5  8.85  1018.05  66.5  0.0  16.0  4.25  10.95   \n",
      "\n",
      "                PM2.5  \n",
      "01-01-2011  22.360000  \n",
      "01-02-2011  14.511111  \n",
      "T        178\n",
      "TM       178\n",
      "Tm       178\n",
      "SLP      178\n",
      "H        178\n",
      "PP       178\n",
      "VV       178\n",
      "V        178\n",
      "VM       178\n",
      "PM2.5      0\n",
      "dtype: int64\n",
      "                T    TM    Tm      SLP     H   PP     VV    V    VM      PM2.5\n",
      "01-01-2012  14.30  27.5  7.25  1019.45  59.0  0.0   8.75  3.8  14.1  20.266667\n",
      "01-02-2012  13.25  18.3  9.45  1020.25  74.0  0.0  13.30  6.1  20.4  24.230000\n",
      "T        179\n",
      "TM       179\n",
      "Tm       179\n",
      "SLP      179\n",
      "H        179\n",
      "PP       179\n",
      "VV       179\n",
      "V        179\n",
      "VM       179\n",
      "PM2.5      0\n",
      "dtype: int64\n",
      "                T    TM    Tm      SLP     H   PP     VV     V     VM  \\\n",
      "01-01-2013  10.50  16.1  5.55  1022.80  54.5  0.0  15.75  4.70  12.95   \n",
      "01-02-2013  15.45  23.6  9.45  1020.05  55.5  0.0  16.10  4.15  18.50   \n",
      "\n",
      "                PM2.5  \n",
      "01-01-2013  30.981250  \n",
      "01-02-2013  13.133333  \n",
      "T        178\n",
      "TM       178\n",
      "Tm       178\n",
      "SLP      178\n",
      "H        178\n",
      "PP       178\n",
      "VV       178\n",
      "V        178\n",
      "VM       178\n",
      "PM2.5      0\n",
      "dtype: int64\n",
      "                T     TM     Tm      SLP     H   PP     VV     V     VM  \\\n",
      "01-01-2014  13.05  20.55   7.25  1019.15  70.5  0.0   7.65   2.9  10.95   \n",
      "01-02-2014  14.75  19.45  11.10  1015.00  27.5  0.0  16.10  11.2  23.05   \n",
      "\n",
      "                PM2.5  \n",
      "01-01-2014  50.430000  \n",
      "01-02-2014   5.666667  \n",
      "T        178\n",
      "TM       178\n",
      "Tm       178\n",
      "SLP      178\n",
      "H        178\n",
      "PP       178\n",
      "VV       178\n",
      "V        178\n",
      "VM       178\n",
      "PM2.5      0\n",
      "dtype: int64\n",
      "                T     TM   Tm      SLP     H   PP     VV     V     VM  \\\n",
      "01-01-2015   8.50  14.45  2.5  1018.85  36.5  0.0  16.10  6.60  19.45   \n",
      "01-02-2015  15.45  22.75  9.7  1016.50  72.5  0.0  15.05  4.45  15.80   \n",
      "\n",
      "                PM2.5  \n",
      "01-01-2015  34.075000  \n",
      "01-02-2015  14.888889  \n",
      "T        178\n",
      "TM       178\n",
      "Tm       178\n",
      "SLP      178\n",
      "H        178\n",
      "PP       178\n",
      "VV       178\n",
      "V        178\n",
      "VM       178\n",
      "PM2.5      0\n",
      "dtype: int64\n",
      "                T     TM    Tm     SLP     H    PP     VV      V     VM  \\\n",
      "01-01-2016  12.05  18.85  5.85  1019.0  24.5  0.00  15.95   6.50  13.85   \n",
      "01-02-2016  10.95  15.30  6.95  1012.0  42.0  7.24  16.00  19.45  45.30   \n",
      "\n",
      "                PM2.5  \n",
      "01-01-2016  16.126316  \n",
      "01-02-2016   3.590909  \n",
      "T        179\n",
      "TM       179\n",
      "Tm       179\n",
      "SLP      179\n",
      "H        179\n",
      "PP       179\n",
      "VV       179\n",
      "V        179\n",
      "VM       179\n",
      "PM2.5      0\n",
      "dtype: int64\n",
      "               T     TM   Tm      SLP     H    PP     VV     V     VM  \\\n",
      "01-01-2017  10.2  15.55  6.1  1012.35  76.5  1.65  15.45  5.85  18.60   \n",
      "01-02-2017  13.9  23.35  8.6  1018.35  64.5  0.00  13.75  4.35  12.95   \n",
      "\n",
      "                PM2.5  \n",
      "01-01-2017  18.370588  \n",
      "01-02-2017  17.577778  \n",
      "T        178\n",
      "TM       178\n",
      "Tm       178\n",
      "SLP      178\n",
      "H        178\n",
      "PP       178\n",
      "VV       178\n",
      "V        178\n",
      "VM       178\n",
      "PM2.5      0\n",
      "dtype: int64\n",
      "               T    TM    Tm      SLP     H   PP     VV     V     VM  \\\n",
      "01-01-2018  13.5  21.7   8.6  1020.05  77.0  0.0   4.70  3.55  12.95   \n",
      "01-02-2018  17.4  26.4  11.4  1014.65  44.5  0.0  15.75  4.05  12.05   \n",
      "\n",
      "                PM2.5  \n",
      "01-01-2018  64.381818  \n",
      "01-02-2018  19.178947  \n",
      "T        176\n",
      "TM       176\n",
      "Tm       176\n",
      "SLP      176\n",
      "H        176\n",
      "PP       176\n",
      "VV       176\n",
      "V        176\n",
      "VM       176\n",
      "PM2.5      0\n",
      "dtype: int64\n",
      "                T    TM    Tm     SLP     H     PP     VV     V     VM  \\\n",
      "01-01-2019  11.25  17.5  4.15  1016.4  23.5   0.00  15.95  5.55  19.40   \n",
      "01-02-2019  13.15  17.5  9.15  1014.8  76.5  22.86  15.75  5.30  12.95   \n",
      "\n",
      "               PM2.5  \n",
      "01-01-2019  8.772727  \n",
      "01-02-2019  7.227273  \n",
      "T        178\n",
      "TM       178\n",
      "Tm       178\n",
      "SLP      178\n",
      "H        178\n",
      "PP       178\n",
      "VV       178\n",
      "V        178\n",
      "VM       178\n",
      "PM2.5      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "### How about null values?\n",
    "\n",
    "dfs = [df_2010, df_2011, df_2012, df_2013, df_2014, df_2015, df_2016, df_2017, df_2018, df_2019]\n",
    "\n",
    "for df in dfs:\n",
    "    print (df.head(2))\n",
    "    print (df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finally, we will concatenate all the DataFrames and drop the index or the 'Date' column.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3652, 10)\n",
      "T        1776\n",
      "TM       1776\n",
      "Tm       1776\n",
      "SLP      1776\n",
      "H        1776\n",
      "PP       1776\n",
      "VV       1776\n",
      "V        1776\n",
      "VM       1776\n",
      "PM2.5       0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T</th>\n",
       "      <th>TM</th>\n",
       "      <th>Tm</th>\n",
       "      <th>SLP</th>\n",
       "      <th>H</th>\n",
       "      <th>PP</th>\n",
       "      <th>VV</th>\n",
       "      <th>V</th>\n",
       "      <th>VM</th>\n",
       "      <th>PM2.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.75</td>\n",
       "      <td>20.85</td>\n",
       "      <td>9.20</td>\n",
       "      <td>1023.95</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.10</td>\n",
       "      <td>4.20</td>\n",
       "      <td>16.75</td>\n",
       "      <td>18.644444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.70</td>\n",
       "      <td>19.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1013.95</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.65</td>\n",
       "      <td>4.50</td>\n",
       "      <td>12.95</td>\n",
       "      <td>26.358824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.80</td>\n",
       "      <td>20.15</td>\n",
       "      <td>9.90</td>\n",
       "      <td>1017.85</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.10</td>\n",
       "      <td>4.90</td>\n",
       "      <td>18.60</td>\n",
       "      <td>10.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.05</td>\n",
       "      <td>16.40</td>\n",
       "      <td>9.50</td>\n",
       "      <td>1013.30</td>\n",
       "      <td>54.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.10</td>\n",
       "      <td>12.50</td>\n",
       "      <td>24.15</td>\n",
       "      <td>4.788889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.15</td>\n",
       "      <td>21.40</td>\n",
       "      <td>12.20</td>\n",
       "      <td>1012.20</td>\n",
       "      <td>48.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.10</td>\n",
       "      <td>11.75</td>\n",
       "      <td>33.25</td>\n",
       "      <td>8.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17.80</td>\n",
       "      <td>23.35</td>\n",
       "      <td>16.15</td>\n",
       "      <td>1015.30</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.45</td>\n",
       "      <td>6.00</td>\n",
       "      <td>14.90</td>\n",
       "      <td>13.260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18.70</td>\n",
       "      <td>22.50</td>\n",
       "      <td>16.30</td>\n",
       "      <td>1010.30</td>\n",
       "      <td>76.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.80</td>\n",
       "      <td>5.85</td>\n",
       "      <td>17.60</td>\n",
       "      <td>18.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>19.30</td>\n",
       "      <td>23.65</td>\n",
       "      <td>16.95</td>\n",
       "      <td>1013.60</td>\n",
       "      <td>70.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.25</td>\n",
       "      <td>6.10</td>\n",
       "      <td>15.80</td>\n",
       "      <td>17.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>19.05</td>\n",
       "      <td>24.70</td>\n",
       "      <td>15.00</td>\n",
       "      <td>1011.70</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.75</td>\n",
       "      <td>7.85</td>\n",
       "      <td>17.60</td>\n",
       "      <td>16.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>23.35</td>\n",
       "      <td>29.10</td>\n",
       "      <td>20.45</td>\n",
       "      <td>1011.50</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.65</td>\n",
       "      <td>5.85</td>\n",
       "      <td>15.80</td>\n",
       "      <td>16.320000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       T     TM     Tm      SLP     H   PP     VV      V     VM      PM2.5\n",
       "0  14.75  20.85   9.20  1023.95  45.0  0.0  16.10   4.20  16.75  18.644444\n",
       "1  13.70  19.00  10.00  1013.95  70.0  0.0  12.65   4.50  12.95  26.358824\n",
       "2  14.80  20.15   9.90  1017.85  69.0  0.0  16.10   4.90  18.60  10.700000\n",
       "3  13.05  16.40   9.50  1013.30  54.5  0.0  16.10  12.50  24.15   4.788889\n",
       "4  17.15  21.40  12.20  1012.20  48.5  0.0  16.10  11.75  33.25   8.733333\n",
       "5  17.80  23.35  16.15  1015.30  68.0  0.0  15.45   6.00  14.90  13.260000\n",
       "6  18.70  22.50  16.30  1010.30  76.5  0.0   7.80   5.85  17.60  18.730000\n",
       "7  19.30  23.65  16.95  1013.60  70.5  0.0  11.25   6.10  15.80  17.466667\n",
       "8  19.05  24.70  15.00  1011.70  69.0  0.0  11.75   7.85  17.60  16.777778\n",
       "9  23.35  29.10  20.45  1011.50  66.0  0.0  15.65   5.85  15.80  16.320000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames = [df_2010, df_2011, df_2012, df_2013, df_2014, df_2015, df_2016, df_2017, df_2018, df_2019]\n",
    "df = pd.concat(frames).reset_index(drop = True)\n",
    "    \n",
    "print (df.shape)\n",
    "print (df.isnull().sum())\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### let's take care of the null rows!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T        0\n",
       "TM       0\n",
       "Tm       0\n",
       "SLP      0\n",
       "H        0\n",
       "PP       0\n",
       "VV       0\n",
       "V        0\n",
       "VM       0\n",
       "PM2.5    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna(axis = 0)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('preprocessed_data_LA.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
